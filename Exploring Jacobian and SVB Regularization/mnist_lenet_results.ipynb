{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results of LeNet Trained on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I display results in terms of accuracy on test data for LeNet models trained on the MNIST dataset using various regularization techniques. The LeNet model and the MNIST dataset were set up as in Hoffman 2019 (for all the models). The MNIST data is preprocessed by normalizing using mean 0.1307 and variance 0.3081. The batch size is 100. The model optimizes using SGD with momentum p = 0.9, and standard cross-entropy loss. Model parameters are initialized using Glorot initialization (See Glorot & Bengio 2010), expect for SVB regularization which uses orthogonal initialization. Models are trained with no regularization, L2 regularization, SVB regularization and Jacobian regularization, both with and without dropout with a dropout rate of p_drop = 0.5. The L2 regularization coefficient and Jacobian regularization coefficient are the same as in Hoffman 2019: l2_lmbd = 0.0005 and lambda_jacobian_reg = 0.01. For SVB regularization I use the hyperparameters svb_freq=600 and svb_eps = 0.05. The learning rate starts at 0.1, and is reduced to 0.01 and 0.001 1/3 and 2/3s into training, respectively. The models are trained for 250 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import jupyter_black\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from scipy import stats\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_generators import data_loader_MNIST\n",
    "from model_classes import LeNet_MNIST\n",
    "from plotting_tools import get_random_img, generate_random_vectors\n",
    "from tools import accuracy, compute_total_variation, ModelInfo\n",
    "\n",
    "jupyter_black.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]             156\n",
      "         MaxPool2d-2            [-1, 6, 14, 14]               0\n",
      "            Conv2d-3           [-1, 16, 10, 10]           2,416\n",
      "         MaxPool2d-4             [-1, 16, 5, 5]               0\n",
      "            Linear-5                  [-1, 120]          48,120\n",
      "           Dropout-6                  [-1, 120]               0\n",
      "            Linear-7                   [-1, 84]          10,164\n",
      "           Dropout-8                   [-1, 84]               0\n",
      "            Linear-9                   [-1, 10]             850\n",
      "================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.06\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 0.30\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load MNIST data\n",
    "train_loader, test_loader = data_loader_MNIST()\n",
    "\n",
    "# Summary of model\n",
    "summary_model = LeNet_MNIST().to(device)\n",
    "summary(summary_model, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "dataset = \"mnist\"\n",
    "\n",
    "# Defining model types and versions\n",
    "model_types = [\"no_reg\", \"l2\", \"jacobi\", \"svb\"]\n",
    "model_versions = [\"\", \"_no_dropout\"]\n",
    "\n",
    "model_names = []\n",
    "\n",
    "for t in model_types:\n",
    "    for v in model_versions:\n",
    "        for i in range(5):\n",
    "            model_names.append(f\"model_{t}{v}_{i}\")\n",
    "\n",
    "models = {name: ModelInfo(name, dataset) for name in model_names}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I calculate the accuracies of each model as a 95% confidence interval. I have trained five models of each variation that I use to calculate the CI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to hold accuracy data\n",
    "accuracy_data = {}\n",
    "\n",
    "# Calculate accuracies with 95% CI for models\n",
    "for t in model_types:\n",
    "    for v in model_versions:\n",
    "        accuracies = []\n",
    "        for i in range(5):  # Assuming 5 versions of each model\n",
    "            model_name = f\"model_{t}{v}_{i}\"\n",
    "            model = models[model_name].model\n",
    "            acc = accuracy(model, test_loader, device)\n",
    "            accuracies.append(acc)\n",
    "\n",
    "        # Calculate mean accuracy\n",
    "        mean_accuracy = np.mean(accuracies)\n",
    "\n",
    "        # Calculate standard error\n",
    "        std_error = stats.sem(accuracies)\n",
    "\n",
    "        # Calculate confidence interval\n",
    "        CI = std_error * stats.t.ppf((1 + 0.95) / 2, len(accuracies) - 1)\n",
    "\n",
    "        # Store results in the data dictionary\n",
    "        accuracy_data[f\"{t}{v if v != '' else '_dropout'}\"] = (mean_accuracy, CI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy +/- CI (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no_regdropout</td>\n",
       "      <td>98.684 +/- 0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_reg_no_dropout</td>\n",
       "      <td>98.872 +/- 0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l2dropout</td>\n",
       "      <td>99.144 +/- 0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l2_no_dropout</td>\n",
       "      <td>99.162 +/- 0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jacobidropout</td>\n",
       "      <td>98.652 +/- 0.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>jacobi_no_dropout</td>\n",
       "      <td>98.846 +/- 0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>svbdropout</td>\n",
       "      <td>98.416 +/- 0.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>svb_no_dropout</td>\n",
       "      <td>98.716 +/- 0.052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model Accuracy +/- CI (%)\n",
       "0      no_regdropout    98.684 +/- 0.074\n",
       "1  no_reg_no_dropout    98.872 +/- 0.088\n",
       "2          l2dropout    99.144 +/- 0.087\n",
       "3      l2_no_dropout    99.162 +/- 0.059\n",
       "4      jacobidropout    98.652 +/- 0.111\n",
       "5  jacobi_no_dropout    98.846 +/- 0.087\n",
       "6         svbdropout    98.416 +/- 0.082\n",
       "7     svb_no_dropout    98.716 +/- 0.052"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert the dictionary into a DataFrame\n",
    "df = pd.DataFrame.from_dict(\n",
    "    accuracy_data, orient=\"index\", columns=[\"Mean Accuracy\", \"Confidence Interval\"]\n",
    ")\n",
    "\n",
    "# Convert the numbers from decimal to percentage and round to four decimal places\n",
    "df = df.multiply(100).round(3)\n",
    "\n",
    "# Create a new column that combines Mean Accuracy and Confidence Interval\n",
    "df[\"Accuracy +/- CI (95%)\"] = df.apply(\n",
    "    lambda row: f\"{row['Mean Accuracy']} +/- {row['Confidence Interval']}\", axis=1\n",
    ")\n",
    "\n",
    "# Drop the original columns\n",
    "df = df.drop(columns=[\"Mean Accuracy\", \"Confidence Interval\"])\n",
    "\n",
    "# Reset the index\n",
    "df = df.reset_index().rename(columns={\"index\": \"Model\"})\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Variation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total variation is a measure for roughness/complexity in images. I generate 25 different images for each model to get a good mean and standard deviation, and give the results as a tabel for each model with the eight models (models with and without dropout) as rows, and the three different zoom levels as columns. The tabel contains the mean and 95 % confidence interval for the total variation for each model at each zoom level, for both isotropic and anisotropic total variation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Isotropic Total Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [19:15<00:00, 144.45s/it]\n"
     ]
    }
   ],
   "source": [
    "# Define zoom levels, number of images, and confidence level for confidence interval calculation\n",
    "zoom_levels = [0.025, 0.01, 0.001]\n",
    "n_images = 10\n",
    "confidence_level = 0.95\n",
    "\n",
    "# Select only the first model of each type (those with index 0)\n",
    "selected_models = [name for name in model_names if name.split(\"_\")[-1] == \"0\"]\n",
    "\n",
    "# Dataframe to store results\n",
    "cols = pd.MultiIndex.from_product([zoom_levels, [\"mean\", \"conf_interval\"]])\n",
    "df_results_isotropic = pd.DataFrame(index=selected_models, columns=cols)\n",
    "\n",
    "# Loop over the selected models\n",
    "for name in tqdm(selected_models):\n",
    "    model = models[name].model  # Get model\n",
    "    model.to(device)\n",
    "    tv_values = {\n",
    "        zoom: [] for zoom in zoom_levels\n",
    "    }  # To store total variation values for each zoom level\n",
    "\n",
    "    # Generate tv values for n_images number of images\n",
    "    for _ in range(n_images):\n",
    "        # Get random image and vectors\n",
    "        img = get_random_img(test_loader)\n",
    "        v1, v2 = generate_random_vectors(img)\n",
    "\n",
    "        # Compute the isotropic total variation of decision boundaries for the current model\n",
    "        # and the generated image at different zoom levels\n",
    "        tv_list = compute_total_variation(\n",
    "            model,\n",
    "            img,\n",
    "            v1,\n",
    "            v2,\n",
    "            device,\n",
    "            resolution=300,\n",
    "            zoom=zoom_levels,\n",
    "            mode=\"isotropic\",\n",
    "        )\n",
    "        for zoom, tv in zip(zoom_levels, tv_list):\n",
    "            tv_values[zoom].append(tv)\n",
    "\n",
    "    # Calculate mean and 95% confidence interval for total variation values at each zoom level\n",
    "    for zoom in zoom_levels:\n",
    "        mean = np.mean(tv_values[zoom])\n",
    "        std_err = np.std(tv_values[zoom]) / np.sqrt(n_images)\n",
    "        conf_interval = stats.t.ppf((1 + confidence_level) / 2, n_images - 1) * std_err\n",
    "        df_results_isotropic.loc[name, (zoom, \"mean\")] = mean\n",
    "        df_results_isotropic.loc[name, (zoom, \"conf_interval\")] = conf_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isotropic Total variation for three different zoom levels (of images generated)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">0.025</th>\n",
       "      <th colspan=\"2\" halign=\"left\">0.010</th>\n",
       "      <th colspan=\"2\" halign=\"left\">0.001</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>conf_interval</th>\n",
       "      <th>mean</th>\n",
       "      <th>conf_interval</th>\n",
       "      <th>mean</th>\n",
       "      <th>conf_interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_no_reg_0</th>\n",
       "      <td>10484.215318</td>\n",
       "      <td>8670.919352</td>\n",
       "      <td>20055.568299</td>\n",
       "      <td>10189.439473</td>\n",
       "      <td>33180.09329</td>\n",
       "      <td>5186.092455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_no_reg_no_dropout_0</th>\n",
       "      <td>1431.393004</td>\n",
       "      <td>539.809508</td>\n",
       "      <td>8738.885322</td>\n",
       "      <td>2161.750419</td>\n",
       "      <td>28302.692786</td>\n",
       "      <td>5066.737596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_l2_0</th>\n",
       "      <td>2504.978695</td>\n",
       "      <td>1421.726025</td>\n",
       "      <td>3611.044961</td>\n",
       "      <td>1348.827846</td>\n",
       "      <td>10970.517191</td>\n",
       "      <td>2177.630834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_l2_no_dropout_0</th>\n",
       "      <td>2002.9516</td>\n",
       "      <td>578.776823</td>\n",
       "      <td>4184.923436</td>\n",
       "      <td>1270.212226</td>\n",
       "      <td>10486.198984</td>\n",
       "      <td>1596.78975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_jacobi_0</th>\n",
       "      <td>12567.630075</td>\n",
       "      <td>7378.907136</td>\n",
       "      <td>14064.39669</td>\n",
       "      <td>4488.636754</td>\n",
       "      <td>7814.213829</td>\n",
       "      <td>2452.030943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_jacobi_no_dropout_0</th>\n",
       "      <td>5333.458297</td>\n",
       "      <td>1783.826237</td>\n",
       "      <td>5462.566915</td>\n",
       "      <td>2025.497287</td>\n",
       "      <td>4819.071154</td>\n",
       "      <td>2370.837468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_svb_0</th>\n",
       "      <td>1747.156649</td>\n",
       "      <td>1169.344075</td>\n",
       "      <td>3112.060829</td>\n",
       "      <td>568.075494</td>\n",
       "      <td>3676.066041</td>\n",
       "      <td>964.389986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_svb_no_dropout_0</th>\n",
       "      <td>1587.808539</td>\n",
       "      <td>1086.578853</td>\n",
       "      <td>3372.276683</td>\n",
       "      <td>1131.283336</td>\n",
       "      <td>10977.061274</td>\n",
       "      <td>3117.005206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  0.025                       0.010  \\\n",
       "                                   mean conf_interval          mean   \n",
       "model_no_reg_0             10484.215318   8670.919352  20055.568299   \n",
       "model_no_reg_no_dropout_0   1431.393004    539.809508   8738.885322   \n",
       "model_l2_0                  2504.978695   1421.726025   3611.044961   \n",
       "model_l2_no_dropout_0         2002.9516    578.776823   4184.923436   \n",
       "model_jacobi_0             12567.630075   7378.907136   14064.39669   \n",
       "model_jacobi_no_dropout_0   5333.458297   1783.826237   5462.566915   \n",
       "model_svb_0                 1747.156649   1169.344075   3112.060829   \n",
       "model_svb_no_dropout_0      1587.808539   1086.578853   3372.276683   \n",
       "\n",
       "                                                0.001                \n",
       "                          conf_interval          mean conf_interval  \n",
       "model_no_reg_0             10189.439473   33180.09329   5186.092455  \n",
       "model_no_reg_no_dropout_0   2161.750419  28302.692786   5066.737596  \n",
       "model_l2_0                  1348.827846  10970.517191   2177.630834  \n",
       "model_l2_no_dropout_0       1270.212226  10486.198984    1596.78975  \n",
       "model_jacobi_0              4488.636754   7814.213829   2452.030943  \n",
       "model_jacobi_no_dropout_0   2025.497287   4819.071154   2370.837468  \n",
       "model_svb_0                  568.075494   3676.066041    964.389986  \n",
       "model_svb_no_dropout_0      1131.283336  10977.061274   3117.005206  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Isotropic Total variation for three different zoom levels (of images generated)\")\n",
    "display(df_results_isotropic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anisotropic Total Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [19:16<00:00, 144.58s/it]\n"
     ]
    }
   ],
   "source": [
    "# Define zoom levels, number of images, and confidence level for confidence interval calculation\n",
    "zoom_levels = [0.025, 0.01, 0.001]\n",
    "n_images = 10\n",
    "confidence_level = 0.95\n",
    "\n",
    "# Select only the first model of each type (those with index 0)\n",
    "selected_models = [name for name in model_names if name.split(\"_\")[-1] == \"0\"]\n",
    "\n",
    "# Dataframe to store results\n",
    "cols = pd.MultiIndex.from_product([zoom_levels, [\"mean\", \"conf_interval\"]])\n",
    "df_results_anisotropic = pd.DataFrame(index=selected_models, columns=cols)\n",
    "\n",
    "# Loop over the selected models\n",
    "for name in tqdm(selected_models):\n",
    "    model = models[name].model  # Get model\n",
    "    model.to(device)\n",
    "    tv_values = {\n",
    "        zoom: [] for zoom in zoom_levels\n",
    "    }  # To store total variation values for each zoom level\n",
    "\n",
    "    # Generate tv values for n_images number of images\n",
    "    for _ in range(n_images):\n",
    "        # Get random image and vectors\n",
    "        img = get_random_img(test_loader)\n",
    "        v1, v2 = generate_random_vectors(img)\n",
    "\n",
    "        # Compute the isotropic total variation of decision boundaries for the current model\n",
    "        # and the generated image at different zoom levels\n",
    "        tv_list = compute_total_variation(\n",
    "            model,\n",
    "            img,\n",
    "            v1,\n",
    "            v2,\n",
    "            device,\n",
    "            resolution=300,\n",
    "            zoom=zoom_levels,\n",
    "            mode=\"anisotropic\",\n",
    "        )\n",
    "        for zoom, tv in zip(zoom_levels, tv_list):\n",
    "            tv_values[zoom].append(tv)\n",
    "\n",
    "    # Calculate mean and 95% confidence interval for total variation values at each zoom level\n",
    "    for zoom in zoom_levels:\n",
    "        mean = np.mean(tv_values[zoom])\n",
    "        std_err = np.std(tv_values[zoom]) / np.sqrt(n_images)\n",
    "        conf_interval = stats.t.ppf((1 + confidence_level) / 2, n_images - 1) * std_err\n",
    "        df_results_anisotropic.loc[name, (zoom, \"mean\")] = mean\n",
    "        df_results_anisotropic.loc[name, (zoom, \"conf_interval\")] = conf_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anisotropic Total variation for three different zoom levels (of images generated)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">0.025</th>\n",
       "      <th colspan=\"2\" halign=\"left\">0.010</th>\n",
       "      <th colspan=\"2\" halign=\"left\">0.001</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>conf_interval</th>\n",
       "      <th>mean</th>\n",
       "      <th>conf_interval</th>\n",
       "      <th>mean</th>\n",
       "      <th>conf_interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_no_reg_0</th>\n",
       "      <td>16489.0</td>\n",
       "      <td>9579.953016</td>\n",
       "      <td>30759.8</td>\n",
       "      <td>8207.474962</td>\n",
       "      <td>38131.4</td>\n",
       "      <td>5955.673933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_no_reg_no_dropout_0</th>\n",
       "      <td>3665.3</td>\n",
       "      <td>2524.393369</td>\n",
       "      <td>10611.8</td>\n",
       "      <td>2894.782772</td>\n",
       "      <td>31105.9</td>\n",
       "      <td>6065.683073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_l2_0</th>\n",
       "      <td>3113.4</td>\n",
       "      <td>1205.333345</td>\n",
       "      <td>4432.4</td>\n",
       "      <td>804.842024</td>\n",
       "      <td>10451.5</td>\n",
       "      <td>1249.21686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_l2_no_dropout_0</th>\n",
       "      <td>2711.6</td>\n",
       "      <td>1535.62887</td>\n",
       "      <td>5235.4</td>\n",
       "      <td>1014.917218</td>\n",
       "      <td>11885.9</td>\n",
       "      <td>2469.744112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_jacobi_0</th>\n",
       "      <td>6393.5</td>\n",
       "      <td>4817.27876</td>\n",
       "      <td>12939.2</td>\n",
       "      <td>7291.401038</td>\n",
       "      <td>12374.6</td>\n",
       "      <td>4050.805704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_jacobi_no_dropout_0</th>\n",
       "      <td>7213.8</td>\n",
       "      <td>1951.732378</td>\n",
       "      <td>8802.0</td>\n",
       "      <td>2345.853662</td>\n",
       "      <td>6056.3</td>\n",
       "      <td>4895.328621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_svb_0</th>\n",
       "      <td>2080.0</td>\n",
       "      <td>1569.950794</td>\n",
       "      <td>2607.2</td>\n",
       "      <td>1023.666724</td>\n",
       "      <td>2889.3</td>\n",
       "      <td>1631.19518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_svb_no_dropout_0</th>\n",
       "      <td>2244.1</td>\n",
       "      <td>1333.621615</td>\n",
       "      <td>5279.2</td>\n",
       "      <td>1569.307022</td>\n",
       "      <td>12895.4</td>\n",
       "      <td>3264.318483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0.025                  0.010                \\\n",
       "                              mean conf_interval     mean conf_interval   \n",
       "model_no_reg_0             16489.0   9579.953016  30759.8   8207.474962   \n",
       "model_no_reg_no_dropout_0   3665.3   2524.393369  10611.8   2894.782772   \n",
       "model_l2_0                  3113.4   1205.333345   4432.4    804.842024   \n",
       "model_l2_no_dropout_0       2711.6    1535.62887   5235.4   1014.917218   \n",
       "model_jacobi_0              6393.5    4817.27876  12939.2   7291.401038   \n",
       "model_jacobi_no_dropout_0   7213.8   1951.732378   8802.0   2345.853662   \n",
       "model_svb_0                 2080.0   1569.950794   2607.2   1023.666724   \n",
       "model_svb_no_dropout_0      2244.1   1333.621615   5279.2   1569.307022   \n",
       "\n",
       "                             0.001                \n",
       "                              mean conf_interval  \n",
       "model_no_reg_0             38131.4   5955.673933  \n",
       "model_no_reg_no_dropout_0  31105.9   6065.683073  \n",
       "model_l2_0                 10451.5    1249.21686  \n",
       "model_l2_no_dropout_0      11885.9   2469.744112  \n",
       "model_jacobi_0             12374.6   4050.805704  \n",
       "model_jacobi_no_dropout_0   6056.3   4895.328621  \n",
       "model_svb_0                 2889.3    1631.19518  \n",
       "model_svb_no_dropout_0     12895.4   3264.318483  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\n",
    "    \"Anisotropic Total variation for three different zoom levels (of images generated)\"\n",
    ")\n",
    "display(df_results_anisotropic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
